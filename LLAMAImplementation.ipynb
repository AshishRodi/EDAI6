{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input prompts saved to input_prompts.txt\n",
      "Predictions saved to output_predictions.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import subprocess\n",
    "\n",
    "# Load the preprocessed numeric data\n",
    "data = pd.read_csv(\"processed_numeric_data.csv\")\n",
    "\n",
    "# Define the columns to use as input features\n",
    "columns = [\"JobLevel\", \"MonthlyIncome\"]  # Removed Age\n",
    "\n",
    "# Convert each row into a text prompt\n",
    "prompts = []\n",
    "for _, row in data.iterrows():\n",
    "    prompt = f\"Employee with JobLevel: {row['JobLevel']}, MonthlyIncome: {row['MonthlyIncome']}. Will they leave?\"\n",
    "    prompts.append(prompt)\n",
    "\n",
    "# Save prompts to a file\n",
    "with open(\"input_prompts.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(prompts))\n",
    "\n",
    "print(\"Input prompts saved to input_prompts.txt\")\n",
    "\n",
    "# Run LLAMA 1B for predictions\n",
    "llama_model_path = \"path/to/llama1b.bin\"  # Update with actual path\n",
    "command = f'./main -m {llama_model_path} --file input_prompts.txt > output_predictions.txt'\n",
    "\n",
    "# Execute the command in the terminal\n",
    "subprocess.run(command, shell=True)\n",
    "\n",
    "print(\"Predictions saved to output_predictions.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"output_predictions.txt\", \"r\") as f:\n",
    "    predictions = f.read()\n",
    "\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Exists\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "llama_path = r\"C:\\Users\\Ashish\\Desktop\\EDAI Project\\Project\\llama.cpp\\build\\bin\\Release\\llama-cli.exe\"\n",
    "print(\"‚úÖ Exists\" if os.path.exists(llama_path) else \"‚ùå File not found!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LLaMA Output:\n",
      " \n",
      "‚ö†Ô∏è LLaMA Errors (if any):\n",
      " ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no\n",
      "ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no\n",
      "ggml_cuda_init: found 1 CUDA devices:\n",
      "  Device 0: NVIDIA GeForce GTX 1650 with Max-Q Design, compute capability 7.5, VMM: yes\n",
      "build: 4819 (becade5d) with MSVC 19.43.34808.0 for x64\n",
      "main: llama backend init\n",
      "main: load the model and apply lora adapter, if any\n",
      "llama_model_load_from_file_impl: using device CUDA0 (NVIDIA GeForce GTX 1650 with Max-Q Design) - 3296 MiB free\n",
      "gguf_init_from_file: failed to open GGUF file '../models/llama-2-7b.Q4_K_M.gguf'\n",
      "llama_model_load: error loading model: llama_model_loader: failed to load model from ../models/llama-2-7b.Q4_K_M.gguf\n",
      "\n",
      "llama_model_load_from_file_impl: failed to load model\n",
      "common_init_from_params: failed to load model '../models/llama-2-7b.Q4_K_M.gguf'\n",
      "main: error: unable to load model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "llama_output = subprocess.run(\n",
    "    [llama_path, \"-m\", \"../models/llama-2-7b.Q4_K_M.gguf\", \"--n-gpu-layers\", \"35\", \"-p\", prompt],\n",
    "    capture_output=True, text=True\n",
    ")\n",
    "\n",
    "# Print both standard output and standard error\n",
    "print(\"‚úÖ LLaMA Output:\\n\", llama_output.stdout)\n",
    "print(\"‚ö†Ô∏è LLaMA Errors (if any):\\n\", llama_output.stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "llama_path = r\"C:\\Users\\Ashish\\Desktop\\EDAI Project\\Project\\llama.cpp\\build\\bin\\Release\\llama-cli.exe\"\n",
    "model_path = r\"C:\\Users\\Ashish\\Desktop\\EDAI Project\\Project\\llama.cpp\\models\\llama-2-7b.Q4_K_M.gguf\"\n",
    "\n",
    "command = f'\"{llama_path}\" -m \"{model_path}\" --n-gpu-layers 35 -p \"Test if this model loads.\"'\n",
    "\n",
    "llama_output = subprocess.run(command, capture_output=True, text=True, shell=True)\n",
    "\n",
    "print(\"‚úÖ LLaMA Output:\\n\", llama_output.stdout)\n",
    "print(\"‚ö†Ô∏è LLaMA Errors (if any):\\n\", llama_output.stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Column Names and Data Types:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1480 entries, 0 to 1479\n",
      "Data columns (total 32 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   DailyRate                 1480 non-null   float64\n",
      " 1   DistanceFromHome          1480 non-null   float64\n",
      " 2   Education                 1480 non-null   float64\n",
      " 3   EnvironmentSatisfaction   1480 non-null   float64\n",
      " 4   HourlyRate                1480 non-null   float64\n",
      " 5   JobInvolvement            1480 non-null   float64\n",
      " 6   JobLevel                  1480 non-null   float64\n",
      " 7   JobSatisfaction           1480 non-null   float64\n",
      " 8   MonthlyIncome             1480 non-null   float64\n",
      " 9   MonthlyRate               1480 non-null   float64\n",
      " 10  NumCompaniesWorked        1480 non-null   float64\n",
      " 11  PercentSalaryHike         1480 non-null   float64\n",
      " 12  PerformanceRating         1480 non-null   float64\n",
      " 13  RelationshipSatisfaction  1480 non-null   float64\n",
      " 14  StandardHours             1480 non-null   float64\n",
      " 15  StockOptionLevel          1480 non-null   float64\n",
      " 16  TotalWorkingYears         1480 non-null   float64\n",
      " 17  TrainingTimesLastYear     1480 non-null   float64\n",
      " 18  WorkLifeBalance           1480 non-null   float64\n",
      " 19  YearsAtCompany            1480 non-null   float64\n",
      " 20  YearsInCurrentRole        1480 non-null   float64\n",
      " 21  YearsSinceLastPromotion   1480 non-null   float64\n",
      " 22  YearsWithCurrManager      1480 non-null   float64\n",
      " 23  AgeGroupEncoded           1480 non-null   float64\n",
      " 24  DepartmentEncoded         1480 non-null   float64\n",
      " 25  GenderEncoded             1480 non-null   float64\n",
      " 26  SalarySlabEncoded         1480 non-null   float64\n",
      " 27  JobRoleEncoded            1480 non-null   float64\n",
      " 28  EducationFieldEncoded     1480 non-null   float64\n",
      " 29  MaritalStatusEncoded      1480 non-null   float64\n",
      " 30  BusinessTravelEncoded     1480 non-null   float64\n",
      " 31  OverTimeEncoded           1480 non-null   float64\n",
      "dtypes: float64(32)\n",
      "memory usage: 370.1 KB\n",
      "None\n",
      "\n",
      "üîç Sample Data:\n",
      "\n",
      "   DailyRate  DistanceFromHome  Education  EnvironmentSatisfaction  \\\n",
      "0   0.091625          0.071429       0.50                 0.666667   \n",
      "1   0.508232          0.321429       0.50                 1.000000   \n",
      "2   0.861847          0.142857       0.50                 0.333333   \n",
      "3   0.132427          0.142857       0.25                 0.333333   \n",
      "4   0.103794          0.250000       0.00                 0.666667   \n",
      "\n",
      "   HourlyRate  JobInvolvement  JobLevel  JobSatisfaction  MonthlyIncome  \\\n",
      "0    0.342857        0.666667       0.0         0.666667       0.021643   \n",
      "1    0.557143        0.333333       0.0         0.666667       0.010058   \n",
      "2    0.557143        0.666667       0.0         0.333333       0.045761   \n",
      "3    0.614286        0.666667       0.0         1.000000       0.002212   \n",
      "4    0.714286        0.666667       0.0         0.666667       0.047130   \n",
      "\n",
      "   MonthlyRate  ...  YearsWithCurrManager  AgeGroupEncoded  DepartmentEncoded  \\\n",
      "0     0.929091  ...                   0.0              0.0                0.5   \n",
      "1     0.306364  ...                   0.0              0.0                0.0   \n",
      "2     0.239510  ...                   0.0              0.0                0.0   \n",
      "3     0.457699  ...                   0.0              0.0                0.5   \n",
      "4     0.460229  ...                   0.0              0.0                0.5   \n",
      "\n",
      "   GenderEncoded  SalarySlabEncoded  JobRoleEncoded  EducationFieldEncoded  \\\n",
      "0            0.0                0.0           0.000                    0.0   \n",
      "1            1.0                0.0           0.125                    0.2   \n",
      "2            0.0                0.0           0.125                    0.4   \n",
      "3            0.0                0.0           0.250                    0.0   \n",
      "4            0.0                0.0           0.000                    0.2   \n",
      "\n",
      "   MaritalStatusEncoded  BusinessTravelEncoded  OverTimeEncoded  \n",
      "0                   0.0                    0.0              0.0  \n",
      "1                   0.0                    0.0              0.0  \n",
      "2                   0.0                    0.5              1.0  \n",
      "3                   0.0                    1.0              0.0  \n",
      "4                   0.0                    1.0              0.0  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your CSV file\n",
    "df = pd.read_csv(\"processed_numeric_data_fixed.csv\")  # Change to your actual file path if needed\n",
    "\n",
    "# Display column names and data types\n",
    "print(\"üìù Column Names and Data Types:\\n\")\n",
    "print(df.info())\n",
    "\n",
    "# Show first few rows\n",
    "print(\"\\nüîç Sample Data:\\n\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DailyRate  DistanceFromHome  Education  EnvironmentSatisfaction  \\\n",
      "0   0.091625          0.071429       0.50                 0.666667   \n",
      "1   0.508232          0.321429       0.50                 1.000000   \n",
      "2   0.861847          0.142857       0.50                 0.333333   \n",
      "3   0.132427          0.142857       0.25                 0.333333   \n",
      "4   0.103794          0.250000       0.00                 0.666667   \n",
      "\n",
      "   HourlyRate  JobInvolvement  JobLevel  JobSatisfaction  MonthlyIncome  \\\n",
      "0    0.342857        0.666667       0.0         0.666667       0.021643   \n",
      "1    0.557143        0.333333       0.0         0.666667       0.010058   \n",
      "2    0.557143        0.666667       0.0         0.333333       0.045761   \n",
      "3    0.614286        0.666667       0.0         1.000000       0.002212   \n",
      "4    0.714286        0.666667       0.0         0.666667       0.047130   \n",
      "\n",
      "   MonthlyRate  ...  YearsWithCurrManager  AgeGroupEncoded  DepartmentEncoded  \\\n",
      "0     0.929091  ...                   0.0              0.0                0.5   \n",
      "1     0.306364  ...                   0.0              0.0                0.0   \n",
      "2     0.239510  ...                   0.0              0.0                0.0   \n",
      "3     0.457699  ...                   0.0              0.0                0.5   \n",
      "4     0.460229  ...                   0.0              0.0                0.5   \n",
      "\n",
      "   GenderEncoded  SalarySlabEncoded  JobRoleEncoded  EducationFieldEncoded  \\\n",
      "0            0.0                0.0           0.000                    0.0   \n",
      "1            1.0                0.0           0.125                    0.2   \n",
      "2            0.0                0.0           0.125                    0.4   \n",
      "3            0.0                0.0           0.250                    0.0   \n",
      "4            0.0                0.0           0.000                    0.2   \n",
      "\n",
      "   MaritalStatusEncoded  BusinessTravelEncoded  OverTimeEncoded  \n",
      "0                   0.0                    0.0              0.0  \n",
      "1                   0.0                    0.0              0.0  \n",
      "2                   0.0                    0.5              1.0  \n",
      "3                   0.0                    1.0              0.0  \n",
      "4                   0.0                    1.0              0.0  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "\n",
      "    Given the following employee details, predict whether they will stay or leave the company and provide reasoning.\n",
      "\n",
      "    Employee Details:\n",
      "    DailyRate                   0.091625\n",
      "DistanceFromHome            0.071429\n",
      "Education                   0.500000\n",
      "EnvironmentSatisfaction     0.666667\n",
      "HourlyRate                  0.342857\n",
      "JobInvolvement              0.666667\n",
      "JobLevel                    0.000000\n",
      "JobSatisfaction             0.666667\n",
      "MonthlyIncome               0.021643\n",
      "MonthlyRate                 0.929091\n",
      "NumCompaniesWorked          0.111111\n",
      "PercentSalaryHike           0.142857\n",
      "PerformanceRating           0.000000\n",
      "RelationshipSatisfaction    0.666667\n",
      "StandardHours               0.000000\n",
      "StockOptionLevel            0.000000\n",
      "TotalWorkingYears           0.000000\n",
      "TrainingTimesLastYear       0.333333\n",
      "WorkLifeBalance             0.666667\n",
      "YearsAtCompany              0.000000\n",
      "YearsInCurrentRole          0.000000\n",
      "YearsSinceLastPromotion     0.000000\n",
      "YearsWithCurrManager        0.000000\n",
      "AgeGroupEncoded             0.000000\n",
      "DepartmentEncoded           0.500000\n",
      "GenderEncoded               0.000000\n",
      "SalarySlabEncoded           0.000000\n",
      "JobRoleEncoded              0.000000\n",
      "EducationFieldEncoded       0.000000\n",
      "MaritalStatusEncoded        0.000000\n",
      "BusinessTravelEncoded       0.000000\n",
      "OverTimeEncoded             0.000000\n",
      "\n",
      "    Prediction: (Stay/Leave)\n",
      "    Reason:\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df_numeric = pd.read_csv(\"processed_numeric_data_fixed.csv\")  # Replace with the correct filename if needed\n",
    "\n",
    "# Check if the dataset loaded properly\n",
    "print(df_numeric.head())  # Display the first few rows\n",
    "\n",
    "def generate_llama_prompt_by_index(row_index, df):\n",
    "    if row_index >= len(df):\n",
    "        return f\"‚ùå Row index {row_index} is out of bounds!\"\n",
    "\n",
    "    # Convert the selected row into a readable format\n",
    "    emp_details = df.iloc[row_index].to_string()\n",
    "    # Construct the LLaMA prompt\n",
    "    prompt = f\"\"\"\n",
    "    Given the following employee details, predict whether they will stay or leave the company and provide reasoning.\n",
    "\n",
    "    Employee Details:\n",
    "    {emp_details}\n",
    "\n",
    "    Prediction: (Stay/Leave)\n",
    "    Reason:\n",
    "    \"\"\"\n",
    "    return prompt\n",
    "\n",
    "# Example usage\n",
    "row_index = 0  # Replace with any valid row index\n",
    "llama_prompt = generate_llama_prompt_by_index(row_index, df_numeric)\n",
    "print(llama_prompt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Given the following employee details, predict whether they will stay or leave the company and provide reasoning.\n",
      "\n",
      "    Employee Details:\n",
      "    DailyRate                   0.091625\n",
      "DistanceFromHome            0.071429\n",
      "Education                   0.500000\n",
      "EnvironmentSatisfaction     0.666667\n",
      "HourlyRate                  0.342857\n",
      "JobInvolvement              0.666667\n",
      "JobLevel                    0.000000\n",
      "JobSatisfaction             0.666667\n",
      "MonthlyIncome               0.021643\n",
      "MonthlyRate                 0.929091\n",
      "NumCompaniesWorked          0.111111\n",
      "PercentSalaryHike           0.142857\n",
      "PerformanceRating           0.000000\n",
      "RelationshipSatisfaction    0.666667\n",
      "StandardHours               0.000000\n",
      "StockOptionLevel            0.000000\n",
      "TotalWorkingYears           0.000000\n",
      "TrainingTimesLastYear       0.333333\n",
      "WorkLifeBalance             0.666667\n",
      "YearsAtCompany              0.000000\n",
      "YearsInCurrentRole          0.000000\n",
      "YearsSinceLastPromotion     0.000000\n",
      "YearsWithCurrManager        0.000000\n",
      "AgeGroupEncoded             0.000000\n",
      "DepartmentEncoded           0.500000\n",
      "GenderEncoded               0.000000\n",
      "SalarySlabEncoded           0.000000\n",
      "JobRoleEncoded              0.000000\n",
      "EducationFieldEncoded       0.000000\n",
      "MaritalStatusEncoded        0.000000\n",
      "BusinessTravelEncoded       0.000000\n",
      "OverTimeEncoded             0.000000\n",
      "\n",
      "    Prediction: (Stay/Leave)\n",
      "    Reason:\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "def generate_llama_prompt_by_index(row_index, df):\n",
    "    if row_index >= len(df):\n",
    "        return f\"‚ùå Row index {row_index} is out of bounds!\"\n",
    "\n",
    "    # Extract the employee's details\n",
    "    emp_details = df.iloc[row_index].to_string()\n",
    "\n",
    "    # Construct the LLaMA prompt\n",
    "    prompt = f\"\"\"\n",
    "    Given the following employee details, predict whether they will stay or leave the company and provide reasoning.\n",
    "\n",
    "    Employee Details:\n",
    "    {emp_details}\n",
    "\n",
    "    Prediction: (Stay/Leave)\n",
    "    Reason:\n",
    "    \"\"\"\n",
    "    return prompt\n",
    "\n",
    "# Example usage\n",
    "row_index = 0  # Change this to select a different employee\n",
    "llama_prompt = generate_llama_prompt_by_index(row_index, df_numeric)\n",
    "print(llama_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def predict_with_llama(prompt):\n",
    "    llama_path = r\"C:\\Users\\Ashish\\Desktop\\EDAI Project\\Project\\llama.cpp\\build\\bin\\Release\\llama-cli.exe\"\n",
    "    model_path = r\"C:\\Users\\Ashish\\Desktop\\EDAI Project\\Project\\llama.cpp\\models\\llama-2-7b.Q4_K_M.gguf\"\n",
    "\n",
    "    # Run LLaMA with the prompt\n",
    "    llama_output = subprocess.run(\n",
    "        [llama_path, \"-m\", model_path, \"--n-gpu-layers\", \"20\", \"-p\", prompt],\n",
    "        capture_output=True, text=True\n",
    "    )\n",
    "    \n",
    "    return f\"üìù LLaMA Prediction:\\n{llama_output.stdout}\"\n",
    "\n",
    "# Run prediction\n",
    "llama_result = predict_with_llama(llama_prompt)\n",
    "print(llama_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def predict_with_llama(prompt):\n",
    "    llama_path = r\"C:\\Users\\Ashish\\Desktop\\EDAI Project\\Project\\llama.cpp\\build\\bin\\Release\\llama-cli.exe\"\n",
    "    model_path = r\"C:\\Users\\Ashish\\Desktop\\EDAI Project\\Project\\llama.cpp\\models\\llama-2-7b.Q2_K.gguf\"\n",
    "\n",
    "    # Run LLaMA with optimized parameters\n",
    "    llama_output = subprocess.run(\n",
    "        [\n",
    "            llama_path, \"-m\", model_path,\n",
    "            \"--n-gpu-layers\", \"30\",  # Reduce GPU load (Try 10 if still slow)\n",
    "            \"--ctx-size\", \"1024\",    # Reduce context window\n",
    "            \"--batch-size\", \"512\",   # Increase batch size (helps performance)\n",
    "            \"-p\", prompt\n",
    "        ],\n",
    "        capture_output=True, text=True\n",
    "    )\n",
    "    \n",
    "    return f\"üìù LLaMA Prediction:\\n{llama_output.stdout}\"\n",
    "\n",
    "# Example prediction\n",
    "llama_result = predict_with_llama(\"Will an employee with 5 years of experience leave or stay?\")\n",
    "print(llama_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvenvironment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
